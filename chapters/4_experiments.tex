\chapter{Experiments}\label{ch:experiments}
In this chapter we will exploit in detail some experiments performed over the RAW Dataset presented in Chatper \ref{ch:raw_dataset}. In particular we will first focus on some object detection experiments performed both with standard shape based approaches as described in Sec. \ref{subsec:template_matching} and deep learning based approaches as described in Sec. \ref{subsec:dl_obj_detection}. Moreover, we will exploit the results of our implementation of the SGM algorithm described in Sec. \ref{subsec:semiglobalmatching} comparing its results with the ground truth depth image created by reconstructing the 3D scene with the ground truth objects pose obtained with the labeling procedure described in Sec. \ref{sec:ground_truth_estim}.

%\section{Region Proposal}\label{sec:exp_region_proposal}
%To do ...

\section{Object Detection}\label{sec:exp_object_detection}
As aleady inoduced in Sec. \ref{sec:objectdetection}, object detection is basically the task of computing the 2D boinging box of a given object within an image. Bounding box is essentially a portion of the image that contains the object. Such basic information is extremely important in robotic perception, especially in robotic vision, where the ability to detect objects in different situations is a crucial point. Our tests basically rely on testing the performances of two different kind of approaches, namely shape based and deep learning.

The tests have been performed on a subset of the RAW Dataset, since the availability of the ground truth for the entire dataset has not been achieved yet, moreover it is not part of the scope of this work. The subset of the RAW Dataset is anyway enough large to permit consistent and coherent statistical evaluations, and it is composed as follows:

\begin{itemize}
	\item \textbf{2 complete scenes}: the tests have been performed using just the first two scenes of the dataset, and just with respect to the data obtained from the experimental FlexSight Sensor, as its performance evaluation is a consistent and important part of the FlexSight project (See Appendix \ref{apx:flexsight});
	\item \textbf{Almost 4 thousand of images}: the two scenes contains both camera left and camera right of the FlexSight Sensor, both with and without projected laser pattern;
	\item \textbf{All the images are labeled}: all the considered images have are accompanied with the relative ground truth 3D position of each object and the relative bounding box as well;
	\item \textbf{5 Different Object Classes}: the involved images only contain 5 object classes of the RAW Dataset, namely: \emph{Distance\_tube}, \emph{M20}, \emph{M20\_100}, \emph{Cover\_plate\_BOX}, \emph{S40\_40\_G};
	\item \textbf{Synthetic data generation}: for the deep learning approaches, data augmentation has been employed. In particular we will see in the following subsections how we trained the YOLO deep neural network described in Sec. \ref{subsec:dl_obj_detection} with 2 different version of the RAW Dataset subset, namely the first is the original one and the second is a synthetic version of it.
\end{itemize}

The results wiil be organized by class of the object and will be expressed in terms of IoU accuracy over the detected bounding box.

\subsection{Shape Based Approach Results - Halcon object detection}\label{subsec:halcon_obj_det_results}
\subsubsection{Experiment Details}
In this experiment, we performed both object localization and detection since the core of the object detection pipeline of the Halcon libs is essentially based on 3D object localization on 2D images, then given the 3D position of the object w.r.t. the camera frame, it is projected onto the 2D image and the bounding box of the object is extracted. Examples of this procedure is given in \figref{fig:iou_example}. Moreover, given the highly customization level that those library has, we investigated object detection performances by considering multiple settings:

\begin{itemize}
	\item \textbf{Single object candidate detection}: Only the object with the highest score is considered
	\item \textbf{Multiple object candidates detection}: We analyzed both the performances using in sequence: \emph{5 candidates}, \emph{4 candidates}, \emph{3 candidates} and \emph{2 candidates}.
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{figures/4_experiments/m20_100_halcon_detection_problems}
    \caption{\textbf{Best Candidate Problems with Halcon Libraries}. The picture depicts an example of erroneous best candidate detection. The candidate that actually refers to the real M20\_100 object is not the one with the highest score. In a single candidate approach the detection would have failed.}
    \label{fig:m20_100_halcon_detection_problems}
\end{figure}

\subsubsection{Experiment Results}
As already anticipated, each result will be presented differentiating for each class of the considered objects. The Tables \ref{tab:halcon_distance_tube_results}, \ref{tab:halcon_M20_results}, \ref{tab:halcon_M20_100_results}, \ref{tab:halcon_Cover_plate_BOX_results} and \ref{tab:halcon_S40_40_G_results} show the accuracy results in terms of Intersection over Union (IoU) for each of the involved object.

As expected, the performances slightly increase when including in the search procedure the highest number of candidates. That is essentially due to the fact that not always the first best candidate, namely the object with the highest score, is exactly the object that we are looking for. If we compare more than one candidate with the ground truth bounding box we find that for some classes of objects, like the \emph{M20\_100}, only when we consider 5 candidates we achieve to detect the actual object, and even in such cases, the one that has the highest score is not the right object (See. \figref{fig:m20_100_halcon_detection_problems} for a better visualization of the described problem).

\begin{table}[!hbt]
\parbox{.45\linewidth}{
	\centering
    \begin{tabular}{| l | l |}
    \hline
    \textbf{Experiment Type} & \textbf{IoU Average} \\ \hline
    \emph{5 candidates} & 0.86190 \\
    \emph{4 candidates} & 0.86190 \\
    \emph{3 candidates} & 0.86190 \\
    \emph{2 candidates} & 0.86190 \\
    \emph{1 candidate} & 0.86190 \\
    \hline
    \end{tabular}
    \caption{\textbf{Halcon IoU avg. scores on Distance\_tube object.}}
    \label{tab:halcon_distance_tube_results}
}
\hfill
\parbox{.45\linewidth}{
	\centering
    \begin{tabular}{| l | l |}
    \hline
    \textbf{Experiment Type} & \textbf{IoU Average} \\ \hline
    \emph{5 candidates} & \textbf{0.74614} \\
    \emph{4 candidates} & \textbf{0.74614} \\
    \emph{3 candidates} & \textbf{0.74614} \\
    \emph{2 candidates} & 0.74418\\
    \emph{1 candidate} & 0.74418\\
    \hline
    \end{tabular}
    \caption{\textbf{Halcon IoU avg. scores on M20 object.}}
    \label{tab:halcon_M20_results}
}
\end{table}

\begin{table}[!hbt]
\parbox{.45\linewidth}{
	\centering
    \begin{tabular}{| l | l |}
    \hline
    \textbf{Experiment Type} & \textbf{IoU Average} \\ \hline
    \emph{5 candidates} & \textbf{0.79750} \\
    \emph{4 candidates} & 0.47585 \\
    \emph{3 candidates} & 0.47585 \\
    \emph{2 candidates} & 0.00000 \\
    \emph{1 candidate} & 0.00000 \\
    \hline
    \end{tabular}
    \caption{\textbf{Halcon IoU avg. scores on M20\_100 object.}}
    \label{tab:halcon_M20_100_results}
}
\hfill
\parbox{.45\linewidth}{
	\centering
    \begin{tabular}{| l | l |}
    \hline
    \textbf{Experiment Type} & \textbf{IoU Average} \\ \hline
    \emph{5 candidates} & \textbf{0.79978} \\
    \emph{4 candidates} & \textbf{0.79978} \\
    \emph{3 candidates} & \textbf{0.79978} \\
    \emph{2 candidates} & \textbf{0.79978} \\
    \emph{1 candidate} & 0.49612 \\
    \hline
    \end{tabular}
    \caption{\textbf{Halcon IoU avg. scores on Cover\_plate\_BOX object.}}
    \label{tab:halcon_Cover_plate_BOX_results}
}
\end{table}

\begin{table}[!hbt]
	\centering
    \begin{tabular}{| l | l |}
    \hline
    \textbf{Experiment Type} & \textbf{IoU Average} \\ \hline
    \emph{5 candidates} & 0.80922 \\
    \emph{4 candidates} & 0.80922 \\
    \emph{3 candidates} & 0.80922 \\
    \emph{2 candidates} & 0.80922 \\
    \emph{1 candidate} & 0.80922 \\
    \hline
    \end{tabular}
    \caption{\textbf{Halcon IoU avg. scores on S40\_40\_G object.}}
    \label{tab:halcon_S40_40_G_results}
\end{table}

\subsection{Deep Learning Approach Results - YOLO}\label{subsec:yolo_obj_det_results}
To do ...

%\section{Stereo Matching}\label{sec:exp_stereo_matcing}
%To do ...

\section{3D Reconstruction}\label{sec:exp_3d_reconstruction}
To do ...

\section{Discussion}\label{sec:exp_discussion}
To do ...